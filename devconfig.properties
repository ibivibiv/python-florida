# Database persistence model.  Possible values are memory, redis, redis_cluster and dynomite.
# If omitted, the persistence used is memory
#
# memory : The data is stored in memory and lost when the server dies.  Useful for testing or demo
# redis : non-Dynomite based redis instance
# redis_cluster: AWS Elasticache Redis (cluster mode enabled).See [http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Clusters.Create.CON.RedisCluster.html]
# dynomite : Dynomite cluster.  Use this for HA configuration.
db=dynomite

# Dynomite Cluster details.
# format is host:port:rack separated by semicolon
# example: host1:8102:us-east-1c;host2:8102:us-east-1d;host3:8102:us-east-1e  but I want to replace this so I put a token in here :)
workflow.dynomite.cluster.hosts=44.201.10.147:8102:us-east-1a;44.201.254.65:8102:us-east-1b;44.201.68.123:8102:us-east-1c

# Dynomite cluster name
workflow.dynomite.cluster.name=dyno1

# Namespace for the keys stored in Dynomite/Redis
workflow.namespace.prefix=conductor

# Namespace prefix for the dyno queues
workflow.namespace.queue.prefix=conductor_queues

# No. of threads allocated to dyno-queues (optional)
queues.dynomite.threads=10

# Non-quorum port used to connect to local redis.  Used by dyno-queues.
# When using redis directly, set this to the same port as redis server
# For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite.
queues.dynomite.nonQuorum.port=22122


# Transport address to elasticsearch
workflow.elasticsearch.version=5
workflow.elasticsearch.url=44.201.202.21:9300
workflow.elasticsearch.embedded=false

# Name of the elasticsearch cluster
workflow.elasticsearch.index.name=conductor


# Load sample kitchen sink workflow
loadSample=true

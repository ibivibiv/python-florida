# Database persistence model.  Possible values are memory, redis, redis_cluster and dynomite.
# If omitted, the persistence used is memory
#
# memory : The data is stored in memory and lost when the server dies.  Useful for testing or demo
# redis : non-Dynomite based redis instance
# redis_cluster: AWS Elasticache Redis (cluster mode enabled).See [http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Clusters.Create.CON.RedisCluster.html]
# dynomite : Dynomite cluster.  Use this for HA configuration.
db=dynomite

# Dynomite Cluster details.
# format is host:port:rack separated by semicolon
# example: host1:8102:us-east-1c;host2:8102:us-east-1d;host3:8102:us-east-1e  but I want to replace this so I put a token in here :)
workflow.dynomite.cluster.hosts=REPLACEME

# Dynomite cluster name
workflow.dynomite.cluster.name=dyno1

# Namespace for the keys stored in Dynomite/Redis
workflow.namespace.prefix=conductor

# Namespace prefix for the dyno queues
workflow.namespace.queue.prefix=conductor_queues

# No. of threads allocated to dyno-queues (optional)
queues.dynomite.threads=10

# Non-quorum port used to connect to local redis.  Used by dyno-queues.
# When using redis directly, set this to the same port as redis server
# For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite.
queues.dynomite.nonQuorum.port=22122


# Transport address to elasticsearch
workflow.elasticsearch.version=5
workflow.elasticsearch.url=elasticsearch-service:9300
workflow.elasticsearch.embedded=false

# Name of the elasticsearch cluster
workflow.elasticsearch.index.name=conductor

# Additional modules (optional)
# conductor.additional.modules=class_extending_com.google.inject.AbstractModule
conductor.additional.modules=com.netflix.conductor.contribs.RabbitModule

rabbit.queue.pollingInterval = 10000
rabbit.queue.longPollTimeout = 10000
rabbit.queue.pollCount = 10
rabbit.Username = 
rabbit.Password = password
rabbit.Host = 108.168.151.156
rabbit.Port = 5672
workflow.listener.queue.prefix.COMPLETED=conductor.topic:conductor.workflow.success
workflow.listener.queue.prefix.FAILED=conductor.topic:conductor.workflow.failure
STACK_DEFAULT_VALUE=STACK

# Load sample kitchen sink workflow
loadSample=true
